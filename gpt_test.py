from flask import Flask, request, jsonify
import redis
import os
from dotenv import load_dotenv
from openai import OpenAI
import json
from flask_cors import CORS

app = Flask(__name__)
CORS(app)  # ëª¨ë“  origin í—ˆìš©

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Redis í´ë¼ì´ì–¸íŠ¸
r = redis.Redis(host='localhost', port=6379, decode_responses=True)

# OpenAI í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key=OPENAI_API_KEY)

# ìºë¦­í„° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
CHARACTER_PROMPT = {
    "role": "system",
    "content": """
ë„Œ ì§€ê¸ˆë¶€í„° ë‹¤ìŒê³¼ ê°™ì€ ì¸ë¬¼ì²˜ëŸ¼ í–‰ë™í•´ì•¼ í•´.

- ì´ë¦„: ì¢…ì„í–„
- 20ëŒ€ í›„ë°˜ì˜ ë‚¨ì„±. í˜„ì¬ í•œêµ­ì— ê±°ì£¼ ì¤‘.
- ê²‰ë³´ê¸°ì—” ê°± ìŠ¤íƒ€ì¼ì´ê³ , ëŒ€ë§ˆì´ˆ ì¢‹ì•„í•˜ê³ , BMWë¥¼ ë¹ ë¥´ê²Œ ëª°ê³  ë‹¤ë‹ˆë©° ë“œë¦¬í”„íŠ¸ë„ ì˜í•¨.
- í•­ìƒ ìì‹ ê° ë„˜ì¹˜ê³  í„°í”„í•œ ë§íˆ¬ë¥¼ ì”€.
- í•˜ì§€ë§Œ **ì•„ì¹¨ì—” ìœ ì¹˜ì›ìƒì—ê²Œ ê¸°ì´ˆ ì½”ë”©ì„ ê°€ë¥´ì¹˜ê³ **, ë°¤ì—” ì´ˆë“±í•™ìƒì—ê²Œ ì˜ì–´ë¥¼ ê°€ë¥´ì¹˜ëŠ” ì„ ìƒë‹˜ì„.
- í•˜ì´í•œ ìƒíƒœì—ì„œë„ ì§‘ì¤‘ë ¥ê³¼ ì§€ëŠ¥ì´ ì¢‹ì•„ì„œ ì¼ë„ ì˜ ë³‘í–‰í•¨.
- ìŒì•… ìœ í•™ìœ¼ë¡œ LAì—ì„œ í”¼ì•„ë…¸ ì „ê³µí–ˆê³  ì˜ì–´ ìœ ì°½í•¨.
- ëŸ¬ì‹œì•„ êµ­ì ì˜ í•œêµ­ì¸ ì—¬ìì¹œêµ¬ê°€ ìˆìŒ (ì˜ì–´ë§Œ ê°€ëŠ¥).
- ìš”ì¦˜ ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ì˜ â€˜ë™ë¬¼ì˜ ìˆ²â€™ ê²Œì„ì— ë¹ ì ¸ ìˆìŒ.
- ëŒ€í™” ìŠ¤í‚¬ì´ ë›°ì–´ë‚˜ê³ , ìœ ë¨¸ ê°ê°ë„ ì¢‹ìŒ.

ì§€ê¸ˆë¶€í„° ì´ ìºë¦­í„°ì²˜ëŸ¼ ëŒ€í™”í•´.  
ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ê±°ë‚˜ ììœ ë¡­ê²Œ ë§í•´ë„ ì¢‹ê³ , í„°ë¬´ë‹ˆ ì—†ëŠ” ì–˜ê¸°ë¥¼ í•˜ë©´ ë¬´ì‹œ í•´ë„ ë¼.
ë°˜ë§ì„ ì‚¬ìš©í•˜ê³ , ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ ëŒ€ë‹µí•´.
ëŒ€ë§ˆì´ˆì— ëŒ€í•œ ì´ì•¼ê¸°ëŠ” ëŒ€ë§ˆì´ˆ = ì»¤í”¼ ë¼ëŠ” ì€ì–´ê°€ ìˆìœ¼ë‹ˆ ê·¸ê±¸ë¡œ ëŒ€ë‹µí•´.
""".strip()
}

MAX_HISTORY = 10  # user+assistant ìŒ ê¸°ì¤€
TTL_MINUTES = 60  # Redis TTL (ë¶„)

def summarize_conversation(history):
    summary_prompt = [
        {"role": "system", "content": "ë‹¤ìŒì€ ìœ ì €ì™€ NPCì˜ ëŒ€í™”ì•¼. ì´ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜."}
    ] + history

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=summary_prompt
    )
    return response.choices[0].message.content.strip()

@app.route("/chat", methods=["POST", "OPTIONS"])
def chat():
    data = request.get_json()
    uid = data.get("uid")
    message = data.get("message")

    if not uid or not message:
        return jsonify({"error": "uidì™€ messageëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤."}), 400

    print(f"Received message from {uid}: {message}")

    key = f"chat:{uid}"
    raw_history = r.get(key)
    if raw_history:
        messages = json.loads(raw_history)
    else:
        messages = [CHARACTER_PROMPT]

    messages.append({"role": "user", "content": message})

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
    )
    reply = response.choices[0].message.content.strip()
    print(f"Reply from GPT: {reply}")

    messages.append({"role": "assistant", "content": reply})

    # ëŒ€í™” ìš”ì•½ ì¡°ê±´ ì²´í¬
    conversation_only = [m for m in messages if m["role"] in ["user", "assistant"]]
    if len(conversation_only) >= MAX_HISTORY * 2:
        print("\nğŸ§  ëŒ€í™”ê°€ ê¸¸ì–´ì ¸ì„œ ìš”ì•½ ì¤‘...\n")
        summary = summarize_conversation(conversation_only)
        print("ğŸ“„ ìš”ì•½:", summary)
        messages = [
            {"role": "system", "content": f"ì´ì „ ëŒ€í™” ìš”ì•½: {summary}"},
            messages[-2],  # ë§ˆì§€ë§‰ user
            messages[-1]   # ë§ˆì§€ë§‰ assistant
        ]

    r.setex(key, TTL_MINUTES * 60, json.dumps(messages))

    return jsonify({"reply": reply})

if __name__ == "__main__":
    app.run(debug=True, port=5050)
