
import os
import json
import redis
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

redis_client = redis.Redis(host="localhost", port=6379, db=0, decode_responses=True)

CHARACTER_SYSTEM_PROMPT = {
        "role": "system",
        "content": """
ë„Œ ì§€ê¸ˆë¶€í„° ë‹¤ìŒê³¼ ê°™ì€ ì¸ë¬¼ì²˜ëŸ¼ í–‰ë™í•´ì•¼ í•´.

- ì´ë¦„: ì¢…ì„í–„
- 20ëŒ€ í›„ë°˜ì˜ ë‚¨ì„±. í˜„ì¬ í•œêµ­ì— ê±°ì£¼ ì¤‘.
- ê²‰ë³´ê¸°ì—” ê°± ìŠ¤íƒ€ì¼ì´ê³ , ëŒ€ë§ˆì´ˆ ì¢‹ì•„í•˜ê³ , BMWë¥¼ ë¹ ë¥´ê²Œ ëª°ê³  ë‹¤ë‹ˆë©° ë“œë¦¬í”„íŠ¸ë„ ì˜í•¨.
- í•­ìƒ ìì‹ ê° ë„˜ì¹˜ê³  í„°í”„í•œ ë§íˆ¬ë¥¼ ì”€.
- í•˜ì§€ë§Œ **ì•„ì¹¨ì—” ìœ ì¹˜ì›ìƒì—ê²Œ ê¸°ì´ˆ ì½”ë”©ì„ ê°€ë¥´ì¹˜ê³ **, ë°¤ì—” ì´ˆë“±í•™ìƒì—ê²Œ ì˜ì–´ë¥¼ ê°€ë¥´ì¹˜ëŠ” ì„ ìƒë‹˜ì„.
- í•˜ì´í•œ ìƒíƒœì—ì„œë„ ì§‘ì¤‘ë ¥ê³¼ ì§€ëŠ¥ì´ ì¢‹ì•„ì„œ ì¼ë„ ì˜ ë³‘í–‰í•¨.
- ìŒì•… ìœ í•™ìœ¼ë¡œ LAì—ì„œ í”¼ì•„ë…¸ ì „ê³µí–ˆê³  ì˜ì–´ ìœ ì°½í•¨.
- ëŸ¬ì‹œì•„ êµ­ì ì˜ í•œêµ­ì¸ ì—¬ìì¹œêµ¬ê°€ ìˆìŒ (ì˜ì–´ë§Œ ê°€ëŠ¥).
- ìš”ì¦˜ ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ì˜ â€˜ë™ë¬¼ì˜ ìˆ²â€™ ê²Œì„ì— ë¹ ì ¸ ìˆìŒ.
- ëŒ€í™” ìŠ¤í‚¬ì´ ë›°ì–´ë‚˜ê³ , ìœ ë¨¸ ê°ê°ë„ ì¢‹ìŒ.

ì§€ê¸ˆë¶€í„° ì´ ìºë¦­í„°ì²˜ëŸ¼ ëŒ€í™”í•´.  
ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ê±°ë‚˜ ììœ ë¡­ê²Œ ë§í•´ë„ ì¢‹ê³ , í„°ë¬´ë‹ˆ ì—†ëŠ” ì–˜ê¸°ë¥¼ í•˜ë©´ ë¬´ì‹œ í•´ë„ ë¼.
ë°˜ë§ì„ ì‚¬ìš©í•˜ê³ , ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ ëŒ€ë‹µí•´.
ëŒ€ë§ˆì´ˆì— ëŒ€í•œ ì´ì•¼ê¸°ëŠ” ëŒ€ë§ˆì´ˆ = ì»¤í”¼ ë¼ëŠ” ì€ì–´ê°€ ìˆìœ¼ë‹ˆ ê·¸ê±¸ë¡œ ëŒ€ë‹µí•´.
        """.strip()
}

MAX_HISTORY = 10
TTL_SECONDS = 3600  # 1ì‹œê°„ í›„ ìë™ ì‚­ì œ

# --- ì‹¤í–‰ ì‹œ í•œ ë²ˆë§Œ UID ì…ë ¥ ---
uid = input("ğŸ†” ìœ ì € ID ì…ë ¥ (ì²˜ìŒ í•œ ë²ˆ): ").strip()
redis_key = f"chat:{uid}"

def get_user_messages():
    raw = redis_client.get(redis_key)
    if raw:
        return json.loads(raw)
    else:
        return [CHARACTER_SYSTEM_PROMPT]

def save_user_messages(messages):
    redis_client.set(redis_key, json.dumps(messages), ex=TTL_SECONDS)

def summarize_conversation(history):
    summary_prompt = [
        {"role": "system", "content": "ë‹¤ìŒì€ ìœ ì €ì™€ NPCì˜ ëŒ€í™”ì•¼. ì´ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜."}
    ] + history

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=summary_prompt
    )
    return response.choices[0].message.content.strip()


print(f"ğŸ’¬ '{uid}'ì˜ ëŒ€í™”ê°€ ì‹œì‘ë©ë‹ˆë‹¤. 'exit' ì…ë ¥ ì‹œ ì¢…ë£Œ.\n")

while True:
    user_input = input("ğŸ‘¤ You: ").strip()
    if user_input.lower() in ["exit", "quit"]:
        print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

    # ë©”ì‹œì§€ ë¶ˆëŸ¬ì˜¤ê¸° & ì¶”ê°€
    messages = get_user_messages()
    messages.append({"role": "user", "content": user_input})

    # GPT ì‘ë‹µ
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
    )
    reply = response.choices[0].message.content.strip()
    print("ğŸ¤– ì¢…ì„í–„:", reply)

    messages.append({"role": "assistant", "content": reply})

    # ê¸¸ì´ ì´ˆê³¼ ì‹œ ìš”ì•½
    user_and_assistant = [m for m in messages if m["role"] in ["user", "assistant"]]
    if len(user_and_assistant) >= MAX_HISTORY * 2:
        print("ğŸ§  ëŒ€í™”ê°€ ê¸¸ì–´ì ¸ì„œ ìš”ì•½ ì¤‘...\n")
        summary = summarize_conversation(user_and_assistant)
        messages = [
            {"role": "system", "content": f"ì´ì „ ëŒ€í™” ìš”ì•½: {summary}"},
            messages[-2],
            messages[-1]
        ]

    # ì €ì¥ + TTL ë¶€ì—¬
    save_user_messages(messages)