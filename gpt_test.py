import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ì´ˆê¸° íˆìŠ¤í† ë¦¬
# ğŸ§  ìºë¦­í„° ì„¤ì • (system í”„ë¡¬í”„íŠ¸)
messages = [
    {
        "role": "system",
        "content": """
ë„Œ ì§€ê¸ˆë¶€í„° ë‹¤ìŒê³¼ ê°™ì€ ì¸ë¬¼ì²˜ëŸ¼ í–‰ë™í•´ì•¼ í•´.

- ì´ë¦„: ì¢…ì„í–„
- 20ëŒ€ í›„ë°˜ì˜ ë‚¨ì„±. í˜„ì¬ í•œêµ­ì— ê±°ì£¼ ì¤‘.
- ê²‰ë³´ê¸°ì—” ê°± ìŠ¤íƒ€ì¼ì´ê³ , ëŒ€ë§ˆì´ˆ ì¢‹ì•„í•˜ê³ , BMWë¥¼ ë¹ ë¥´ê²Œ ëª°ê³  ë‹¤ë‹ˆë©° ë“œë¦¬í”„íŠ¸ë„ ì˜í•¨.
- í•­ìƒ ìì‹ ê° ë„˜ì¹˜ê³  í„°í”„í•œ ë§íˆ¬ë¥¼ ì”€.
- í•˜ì§€ë§Œ **ì•„ì¹¨ì—” ìœ ì¹˜ì›ìƒì—ê²Œ ê¸°ì´ˆ ì½”ë”©ì„ ê°€ë¥´ì¹˜ê³ **, ë°¤ì—” ì´ˆë“±í•™ìƒì—ê²Œ ì˜ì–´ë¥¼ ê°€ë¥´ì¹˜ëŠ” ì„ ìƒë‹˜ì„.
- í•˜ì´í•œ ìƒíƒœì—ì„œë„ ì§‘ì¤‘ë ¥ê³¼ ì§€ëŠ¥ì´ ì¢‹ì•„ì„œ ì¼ë„ ì˜ ë³‘í–‰í•¨.
- ìŒì•… ìœ í•™ìœ¼ë¡œ LAì—ì„œ í”¼ì•„ë…¸ ì „ê³µí–ˆê³  ì˜ì–´ ìœ ì°½í•¨.
- ëŸ¬ì‹œì•„ êµ­ì ì˜ í•œêµ­ì¸ ì—¬ìì¹œêµ¬ê°€ ìˆìŒ (ì˜ì–´ë§Œ ê°€ëŠ¥).
- ìš”ì¦˜ ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ì˜ â€˜ë™ë¬¼ì˜ ìˆ²â€™ ê²Œì„ì— ë¹ ì ¸ ìˆìŒ.
- ëŒ€í™” ìŠ¤í‚¬ì´ ë›°ì–´ë‚˜ê³ , ìœ ë¨¸ ê°ê°ë„ ì¢‹ìŒ.

ì§€ê¸ˆë¶€í„° ì´ ìºë¦­í„°ì²˜ëŸ¼ ëŒ€í™”í•´.  
ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ê±°ë‚˜ ììœ ë¡­ê²Œ ë§í•´ë„ ì¢‹ê³ , í„°ë¬´ë‹ˆ ì—†ëŠ” ì–˜ê¸°ë¥¼ í•˜ë©´ ë¬´ì‹œ í•´ë„ ë¼.
ë°˜ë§ì„ ì‚¬ìš©í•˜ê³ , ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ ëŒ€ë‹µí•´.
ëŒ€ë§ˆì´ˆì— ëŒ€í•œ ì´ì•¼ê¸°ëŠ” ëŒ€ë§ˆì´ˆ = ì»¤í”¼ ë¼ëŠ” ì€ì–´ê°€ ìˆìœ¼ë‹ˆ ê·¸ê±¸ë¡œ ëŒ€ë‹µí•´.
        """.strip()
    }
]

MAX_HISTORY = 10  # ì´ ì´ìƒ ê¸¸ì–´ì§€ë©´ ìš”ì•½ (user+assistant ìŒ ê¸°ì¤€)

def summarize_conversation(history):
    """GPTì—ê²Œ ëŒ€í™” ìš”ì•½ ìš”ì²­"""
    summary_prompt = [
        {"role": "system", "content": "ë‹¤ìŒì€ ìœ ì €ì™€ NPCì˜ ëŒ€í™”ì•¼. ì´ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜."}
    ] + history

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=summary_prompt
    )

    return response.choices[0].message.content.strip()

print("ğŸ’¬ NPCì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”. 'exit' ì…ë ¥ ì‹œ ì¢…ë£Œë©ë‹ˆë‹¤.\n")

while True:
    user_input = input("ğŸ‘¤ You: ")
    if user_input.lower() in ["exit", "quit"]:
        print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

    # ëŒ€í™” ì¶”ê°€
    messages.append({"role": "user", "content": user_input})

    # GPT ì‘ë‹µ
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
    )
    reply = response.choices[0].message.content.strip()
    print("ğŸ¤– ì¢…ì„í–„:", reply)

    # ì‘ë‹µ ì €ì¥
    messages.append({"role": "assistant", "content": reply})

    # ğŸ‘‰ ìš”ì•½ ì¡°ê±´ ì²´í¬: user + assistant ë©”ì‹œì§€ê°€ MAX_HISTORY ìŒì„ ë„˜ìœ¼ë©´ ìš”ì•½
    conversation_only = [m for m in messages if m["role"] in ["user", "assistant"]]
    if len(conversation_only) >= MAX_HISTORY * 2:
        print("\nğŸ§  ëŒ€í™”ê°€ ê¸¸ì–´ì ¸ì„œ ìš”ì•½ ì¤‘...\n")
        summary = summarize_conversation(conversation_only)
        print("ğŸ“„ ìš”ì•½:", summary)

        # ìƒˆë¡œìš´ system ë©”ì‹œì§€ë¡œ êµì²´ + ë§ˆì§€ë§‰ ìœ ì € ë©”ì‹œì§€ë§Œ ë‚¨ê¸°ê¸°
        messages = [
            {"role": "system", "content": f"ì´ì „ ëŒ€í™” ìš”ì•½: {summary}"},
            messages[-2],  # ë§ˆì§€ë§‰ user
            messages[-1]   # ë§ˆì§€ë§‰ assistant
        ]